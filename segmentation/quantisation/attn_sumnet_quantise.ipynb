{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home/rakshith/.conda/envs/rak-env/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/rakshith/.conda/envs/rak-env/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/rakshith/.conda/envs/rak-env/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/rakshith/.conda/envs/rak-env/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/rakshith/.conda/envs/rak-env/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/rakshith/.conda/envs/rak-env/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/rakshith/.conda/envs/rak-env/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/rakshith/.conda/envs/rak-env/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from self_attn_sumnet import FullAttenSUMNet\n",
    "from train import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FullAttenSUMNet(in_ch=1, out_ch=2)\n",
    "model_path = '/home/rakshith/miccai_2022/model_weights/segmentation/ssa_seg_adam_1e4_e15_re/'\n",
    "checkpoint= torch.load(model_path+'model_best_dice.pt')\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.rel_h', 'conv1.rel_w', 'conv1.key_conv.weight', 'conv1.query_conv.weight', 'conv1.value_conv.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'conv2.rel_h', 'conv2.rel_w', 'conv2.key_conv.weight', 'conv2.query_conv.weight', 'conv2.value_conv.weight', 'bn2.weight', 'bn2.bias', 'bn2.running_mean', 'bn2.running_var', 'bn2.num_batches_tracked', 'conv3a.rel_h', 'conv3a.rel_w', 'conv3a.key_conv.weight', 'conv3a.query_conv.weight', 'conv3a.value_conv.weight', 'bn3a.weight', 'bn3a.bias', 'bn3a.running_mean', 'bn3a.running_var', 'bn3a.num_batches_tracked', 'conv3b.rel_h', 'conv3b.rel_w', 'conv3b.key_conv.weight', 'conv3b.query_conv.weight', 'conv3b.value_conv.weight', 'bn3b.weight', 'bn3b.bias', 'bn3b.running_mean', 'bn3b.running_var', 'bn3b.num_batches_tracked', 'conv4a.rel_h', 'conv4a.rel_w', 'conv4a.key_conv.weight', 'conv4a.query_conv.weight', 'conv4a.value_conv.weight', 'bn4a.weight', 'bn4a.bias', 'bn4a.running_mean', 'bn4a.running_var', 'bn4a.num_batches_tracked', 'conv4b.rel_h', 'conv4b.rel_w', 'conv4b.key_conv.weight', 'conv4b.query_conv.weight', 'conv4b.value_conv.weight', 'bn4b.weight', 'bn4b.bias', 'bn4b.running_mean', 'bn4b.running_var', 'bn4b.num_batches_tracked', 'conv5a.rel_h', 'conv5a.rel_w', 'conv5a.key_conv.weight', 'conv5a.query_conv.weight', 'conv5a.value_conv.weight', 'bn5a.weight', 'bn5a.bias', 'bn5a.running_mean', 'bn5a.running_var', 'bn5a.num_batches_tracked', 'conv5b.rel_h', 'conv5b.rel_w', 'conv5b.key_conv.weight', 'conv5b.query_conv.weight', 'conv5b.value_conv.weight', 'bn5b.weight', 'bn5b.bias', 'bn5b.running_mean', 'bn5b.running_var', 'bn5b.num_batches_tracked', 'donv5b.rel_h', 'donv5b.rel_w', 'donv5b.key_conv.weight', 'donv5b.query_conv.weight', 'donv5b.value_conv.weight', 'donv5a.rel_h', 'donv5a.rel_w', 'donv5a.key_conv.weight', 'donv5a.query_conv.weight', 'donv5a.value_conv.weight', 'donv4b.rel_h', 'donv4b.rel_w', 'donv4b.key_conv.weight', 'donv4b.query_conv.weight', 'donv4b.value_conv.weight', 'donv4a.rel_h', 'donv4a.rel_w', 'donv4a.key_conv.weight', 'donv4a.query_conv.weight', 'donv4a.value_conv.weight', 'donv3b.rel_h', 'donv3b.rel_w', 'donv3b.key_conv.weight', 'donv3b.query_conv.weight', 'donv3b.value_conv.weight', 'donv3a.rel_h', 'donv3a.rel_w', 'donv3a.key_conv.weight', 'donv3a.query_conv.weight', 'donv3a.value_conv.weight', 'donv2.rel_h', 'donv2.rel_w', 'donv2.key_conv.weight', 'donv2.query_conv.weight', 'donv2.value_conv.weight', 'donv1.rel_h', 'donv1.rel_w', 'donv1.key_conv.weight', 'donv1.query_conv.weight', 'donv1.value_conv.weight', 'output.rel_h', 'output.rel_w', 'output.key_conv.weight', 'output.query_conv.weight', 'output.value_conv.weight'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_out_h torch.Size([1, 32, 512, 512, 3, 3])\n",
      "k_out_w torch.Size([1, 32, 512, 512, 3, 3])\n",
      "rel_h torch.Size([32, 1, 1, 3, 1])\n",
      "rel_w torch.Size([32, 1, 1, 1, 3])\n",
      "k_out_h torch.Size([1, 64, 512, 512, 3, 3])\n",
      "k_out_w torch.Size([1, 64, 512, 512, 3, 3])\n",
      "rel_h torch.Size([64, 1, 1, 3, 1])\n",
      "rel_w torch.Size([64, 1, 1, 1, 3])\n",
      "k_out_h torch.Size([1, 128, 256, 256, 3, 3])\n",
      "k_out_w torch.Size([1, 128, 256, 256, 3, 3])\n",
      "rel_h torch.Size([128, 1, 1, 3, 1])\n",
      "rel_w torch.Size([128, 1, 1, 1, 3])\n",
      "k_out_h torch.Size([1, 128, 256, 256, 3, 3])\n",
      "k_out_w torch.Size([1, 128, 256, 256, 3, 3])\n",
      "rel_h torch.Size([128, 1, 1, 3, 1])\n",
      "rel_w torch.Size([128, 1, 1, 1, 3])\n",
      "k_out_h torch.Size([1, 256, 128, 128, 3, 3])\n",
      "k_out_w torch.Size([1, 256, 128, 128, 3, 3])\n",
      "rel_h torch.Size([256, 1, 1, 3, 1])\n",
      "rel_w torch.Size([256, 1, 1, 1, 3])\n",
      "k_out_h torch.Size([1, 256, 128, 128, 3, 3])\n",
      "k_out_w torch.Size([1, 256, 128, 128, 3, 3])\n",
      "rel_h torch.Size([256, 1, 1, 3, 1])\n",
      "rel_w torch.Size([256, 1, 1, 1, 3])\n",
      "k_out_h torch.Size([1, 256, 64, 64, 3, 3])\n",
      "k_out_w torch.Size([1, 256, 64, 64, 3, 3])\n",
      "rel_h torch.Size([256, 1, 1, 3, 1])\n",
      "rel_w torch.Size([256, 1, 1, 1, 3])\n",
      "k_out_h torch.Size([1, 256, 64, 64, 3, 3])\n",
      "k_out_w torch.Size([1, 256, 64, 64, 3, 3])\n",
      "rel_h torch.Size([256, 1, 1, 3, 1])\n",
      "rel_w torch.Size([256, 1, 1, 1, 3])\n",
      "k_out_h torch.Size([1, 256, 64, 64, 3, 3])\n",
      "k_out_w torch.Size([1, 256, 64, 64, 3, 3])\n",
      "rel_h torch.Size([256, 1, 1, 3, 1])\n",
      "rel_w torch.Size([256, 1, 1, 1, 3])\n",
      "k_out_h torch.Size([1, 256, 64, 64, 3, 3])\n",
      "k_out_w torch.Size([1, 256, 64, 64, 3, 3])\n",
      "rel_h torch.Size([256, 1, 1, 3, 1])\n",
      "rel_w torch.Size([256, 1, 1, 1, 3])\n",
      "k_out_h torch.Size([1, 256, 128, 128, 3, 3])\n",
      "k_out_w torch.Size([1, 256, 128, 128, 3, 3])\n",
      "rel_h torch.Size([256, 1, 1, 3, 1])\n",
      "rel_w torch.Size([256, 1, 1, 1, 3])\n",
      "k_out_h torch.Size([1, 128, 128, 128, 3, 3])\n",
      "k_out_w torch.Size([1, 128, 128, 128, 3, 3])\n",
      "rel_h torch.Size([128, 1, 1, 3, 1])\n",
      "rel_w torch.Size([128, 1, 1, 1, 3])\n",
      "k_out_h torch.Size([1, 128, 256, 256, 3, 3])\n",
      "k_out_w torch.Size([1, 128, 256, 256, 3, 3])\n",
      "rel_h torch.Size([128, 1, 1, 3, 1])\n",
      "rel_w torch.Size([128, 1, 1, 1, 3])\n",
      "k_out_h torch.Size([1, 64, 256, 256, 3, 3])\n",
      "k_out_w torch.Size([1, 64, 256, 256, 3, 3])\n",
      "rel_h torch.Size([64, 1, 1, 3, 1])\n",
      "rel_w torch.Size([64, 1, 1, 1, 3])\n",
      "k_out_h torch.Size([1, 32, 512, 512, 3, 3])\n",
      "k_out_w torch.Size([1, 32, 512, 512, 3, 3])\n",
      "rel_h torch.Size([32, 1, 1, 3, 1])\n",
      "rel_w torch.Size([32, 1, 1, 1, 3])\n",
      "k_out_h torch.Size([1, 16, 512, 512, 3, 3])\n",
      "k_out_w torch.Size([1, 16, 512, 512, 3, 3])\n",
      "rel_h torch.Size([16, 1, 1, 3, 1])\n",
      "rel_w torch.Size([16, 1, 1, 1, 3])\n",
      "k_out_h torch.Size([1, 1, 512, 512, 1, 1])\n",
      "k_out_w torch.Size([1, 1, 512, 512, 1, 1])\n",
      "rel_h torch.Size([1, 1, 1, 1, 1])\n",
      "rel_w torch.Size([1, 1, 1, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 31.5839,  16.7555,  15.8482,  ...,   8.3786,  16.0632,  14.7094],\n",
       "          [ 24.3934,  -3.4504,   6.2092,  ...,  30.8628,  26.8913,  36.8055],\n",
       "          [ 37.6056,  25.2991,  24.9170,  ...,  21.8068,  39.3860,  36.2315],\n",
       "          ...,\n",
       "          [ 31.6302,   7.6537,  25.6618,  ...,  26.5776,  15.1442,  16.4952],\n",
       "          [  5.7001,  40.9816,   7.9990,  ...,  31.9025,  34.7458,  38.6496],\n",
       "          [ 10.0325,   6.7424,   3.2536,  ...,   8.2355,  -1.3150,   9.2789]],\n",
       "\n",
       "         [[-14.7194,  -6.3299,  -2.2152,  ...,   5.6979, -12.0606, -11.5009],\n",
       "          [-10.3524,  15.2573,   1.5416,  ...,  -4.9930,  -8.8091, -26.2781],\n",
       "          [-15.9434,  -7.5940, -15.4722,  ...,   1.0322, -14.5425, -16.3925],\n",
       "          ...,\n",
       "          [-12.5429,  -0.9104, -10.8055,  ..., -11.9812,  -2.0164,  -5.8728],\n",
       "          [ -1.9018, -11.6187,  -5.1707,  ..., -15.9196, -20.6752, -17.6627],\n",
       "          [ -3.9344,  -6.8229,  10.1032,  ...,  -7.4265,   7.5038,   1.9399]]]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn((1,1,512,512))\n",
    "model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.quantization import get_default_qconfig\n",
    "# Note that this is temporary, we'll expose these functions to torch.quantization after official releasee\n",
    "from torch.quantization.quantize_fx import prepare_fx, convert_fx\n",
    "import json\n",
    "from torch.utils import data\n",
    "from dataloader import LiverDataLoader\n",
    "\n",
    "model_name = 'ssa_seg_adam_1e4_e15_re_quantised'\n",
    "config = {\n",
    "        \"savepath\":\"/home/rakshith/miccai_2022/model_weights/segmentation/\"+model_name+\"/\",\n",
    "        \"datapath\": \"/home/rakshith/Datasets/Task03_Liver/np_array_slices/\",\n",
    "        \"data_split\": \"/home/rakshith/miccai_2022/segmentation/train_valid_split.json\",\n",
    "        \"out_ch\" : 2,\n",
    "        \"model_name\":model_name,\n",
    "        \"model\" : 'ssa_quant',\n",
    "        \"quantised\": 1\n",
    "    }\n",
    "\n",
    "data_split = config['data_split']\n",
    "\n",
    "with open('/home/rakshith/miccai_2022/segmentation/train_valid_split.json') as f3:\n",
    "    data_split = json.load(f3)\n",
    "file_list = data_split['valid'][:10]\n",
    "data_path = '/home/rakshith/Datasets/Task03_Liver/np_array_slices/'\n",
    "\n",
    "testDset = LiverDataLoader(datapath=data_path, file_list=file_list,is_transform=True)\n",
    "\n",
    "testDataLoader = data.DataLoader(\n",
    "                            testDset, batch_size=1, drop_last=True,\n",
    "                            shuffle=False, num_workers=2, pin_memory=True)\n",
    "model.eval()\n",
    "qconfig = get_default_qconfig(\"fbgemm\")\n",
    "qconfig_dict = {\"\": qconfig}\n",
    "prepare_custom_config_dict = {\n",
    "    # option 1\n",
    "    \"non_traceable_module_name\": [\"pool\"],\n",
    "}\n",
    "def calibrate(model, data_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for image, target,_ in data_loader:\n",
    "            model(image)\n",
    "\n",
    "prepared_model = prepare_fx(model, qconfig_dict,prepare_custom_config_dict=prepare_custom_config_dict,)  # fuse modules and insert observers\n",
    "calibrate(prepared_model, testDataLoader)  # run calibration on sample data\n",
    "quantized_model = convert_fx(prepared_model)  # convert the calibrated model to a quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Add operands must be the same size!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6af49044dcc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantized_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miccai_2022/segmentation/train.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(config, model)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mseg_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_seg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m             \u001b[0mnet_out_sf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rak-env/lib/python3.7/site-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36mwrapped_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexcepthook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_full_traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexcepthook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_excepthook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rak-env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<eval_with_key_5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mconv1_scale_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_scale_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mconv1_zero_point_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_zero_point_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0madd_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantize_per_tensor_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantize_per_tensor_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1_scale_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1_zero_point_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mquantize_per_tensor_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantize_per_tensor_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv1_scale_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv1_zero_point_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mconv1_rel_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrel_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mconv1_input_scale_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_input_scale_4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Add operands must be the same size!"
     ]
    }
   ],
   "source": [
    "test(config, quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02d518ac1fc09ef5dc4eabe4d9fe87a26d09bc9551d9c7d27686a6ac8a51ace1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('rak-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
