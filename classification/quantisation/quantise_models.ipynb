{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from model_quant import AttNet \n",
    "from train import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AttNet(in_channels=1, num_classes=15)\n",
    "model_path = '/home/rakshith/miccai_2022/model_weights/classification/ssa_adam_1e4_e15_bce/'\n",
    "model.load_state_dict(torch.load(model_path+'model_best.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rakshith/.conda/envs/rak-env/lib/python3.7/site-packages/torch/quantization/observer.py:123: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  reduce_range will be deprecated in a future release of PyTorch.\"\n",
      "/home/rakshith/.conda/envs/rak-env/lib/python3.7/site-packages/torch/quantization/observer.py:957: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  Returning default scale and zero point \"\n"
     ]
    }
   ],
   "source": [
    "backend = \"fbgemm\"\n",
    "model.eval()\n",
    "model.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "torch.backends.quantized.engine = backend\n",
    "model_static_quantized = torch.quantization.prepare(model, inplace=False)\n",
    "model_static_quantized = torch.quantization.convert(model_static_quantized, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "                \"savepath\":\"/home/rakshith/miccai_2022/model_weights/classification/quantised_attnet/\",\n",
    "                \"model\" : \"quantised\"\n",
    "            }\n",
    "# test(config, model_static_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# torch.cuda.set_device(1)\n",
    "model = torchvision.models.quantization.resnet18(pretrained=False)\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 15)\n",
    "model_path = '/home/rakshith/miccai_2022/model_weights/classification/resnet18_adam_1e4_e15_bce/'\n",
    "model.load_state_dict(torch.load(model_path+'model_best.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rakshith/.conda/envs/rak-env/lib/python3.7/site-packages/torch/quantization/observer.py:123: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  reduce_range will be deprecated in a future release of PyTorch.\"\n",
      "/home/rakshith/.conda/envs/rak-env/lib/python3.7/site-packages/torch/quantization/observer.py:957: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  Returning default scale and zero point \"\n"
     ]
    }
   ],
   "source": [
    "backend = \"fbgemm\"\n",
    "model.eval()\n",
    "model.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "torch.backends.quantized.engine = backend\n",
    "model_static_quantized = torch.quantization.prepare(model, inplace=False)\n",
    "model_static_quantized = torch.quantization.convert(model_static_quantized, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "                \"savepath\":\"/home/rakshith/miccai_2022/model_weights/classification/new_results_1000imgs/quantised_resnet18/\",\n",
    "                \"model\" : \"quantised\"\n",
    "            }\n",
    "# test(config, model_static_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_size(mdl):\n",
    "    torch.save(mdl.state_dict(), config['savepath']+\"att_quant.pth\")\n",
    "    print(\"%.2f MB\" %(os.path.getsize(config['savepath']+\"att_quant.pth\")/1e6))\n",
    "# print_model_size(model_static_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.quantization.resnet50(pretrained=False)\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 15)\n",
    "model_path = '/home/rakshith/miccai_2022/model_weights/classification/resnet50_adam_1e4_e15_bce/'\n",
    "model.load_state_dict(torch.load(model_path+'model_best.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = \"fbgemm\"\n",
    "model.eval()\n",
    "model.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "torch.backends.quantized.engine = backend\n",
    "model_static_quantized_50 = torch.quantization.prepare(model, inplace=False)\n",
    "model_static_quantized_50 = torch.quantization.convert(model_static_quantized_50, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:32<00:00,  6.56it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "                \"savepath\":\"/home/rakshith/miccai_2022/model_weights/classification/new_results_1000imgs/quantised_resnet50/\",\n",
    "                \"model\" : \"quantised\"\n",
    "            }\n",
    "test(config, model_static_quantized_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.52 MB\n"
     ]
    }
   ],
   "source": [
    "def print_model_size(mdl):\n",
    "    torch.save(mdl.state_dict(), config['savepath']+\"resnet50_quant.pth\")\n",
    "    print(\"%.2f MB\" %(os.path.getsize(config['savepath']+\"resnet50_quant.pth\")/1e6))\n",
    "print_model_size(model_static_quantized_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.72 MB\n"
     ]
    }
   ],
   "source": [
    "print_model_size(model_static_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02d518ac1fc09ef5dc4eabe4d9fe87a26d09bc9551d9c7d27686a6ac8a51ace1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('rak-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
